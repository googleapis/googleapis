// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package google.cloud.aiplatform.v1beta1;

import "google/api/field_behavior.proto";
import "google/cloud/aiplatform/v1beta1/content.proto";

option csharp_namespace = "Google.Cloud.AIPlatform.V1Beta1";
option go_package = "cloud.google.com/go/aiplatform/apiv1beta1/aiplatformpb;aiplatformpb";
option java_multiple_files = true;
option java_outer_classname = "UsageMetadataProto";
option java_package = "com.google.cloud.aiplatform.v1beta1";
option php_namespace = "Google\\Cloud\\AIPlatform\\V1beta1";
option ruby_package = "Google::Cloud::AIPlatform::V1beta1";

// Usage metadata about the content generation request and response.
// This message provides a detailed breakdown of token usage and other
// relevant metrics.
message UsageMetadata {
  // The type of traffic that this request was processed with, indicating which
  // quota gets consumed.
  enum TrafficType {
    // Unspecified request traffic type.
    TRAFFIC_TYPE_UNSPECIFIED = 0;

    // Type for Pay-As-You-Go traffic.
    ON_DEMAND = 1;

    // Type for Provisioned Throughput traffic.
    PROVISIONED_THROUGHPUT = 2;
  }

  // The total number of tokens in the prompt. This includes any text, images,
  // or other media provided in the request. When `cached_content` is set,
  // this also includes the number of tokens in the cached content.
  int32 prompt_token_count = 1;

  // The total number of tokens in the generated candidates.
  int32 candidates_token_count = 2;

  // The total number of tokens for the entire request. This is the sum of
  // `prompt_token_count`, `candidates_token_count`,
  // `tool_use_prompt_token_count`, and `thoughts_token_count`.
  int32 total_token_count = 3;

  // Output only. The number of tokens in the results from tool executions,
  // which are provided back to the model as input, if applicable.
  int32 tool_use_prompt_token_count = 13
      [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. The number of tokens that were part of the model's generated
  // "thoughts" output, if applicable.
  int32 thoughts_token_count = 14 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. The number of tokens in the cached content that was used for
  // this request.
  int32 cached_content_token_count = 5
      [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. A detailed breakdown of the token count for each modality in
  // the prompt.
  repeated ModalityTokenCount prompt_tokens_details = 9
      [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. A detailed breakdown of the token count for each modality in
  // the cached content.
  repeated ModalityTokenCount cache_tokens_details = 10
      [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. A detailed breakdown of the token count for each modality in
  // the generated candidates.
  repeated ModalityTokenCount candidates_tokens_details = 11
      [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. A detailed breakdown by modality of the token counts from the
  // results of tool executions, which are provided back to the model as input.
  repeated ModalityTokenCount tool_use_prompt_tokens_details = 12
      [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. The traffic type for this request.
  TrafficType traffic_type = 8 [(google.api.field_behavior) = OUTPUT_ONLY];
}
