// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package google.cloud.dataplex.v1;

import "google/api/resource.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/timestamp.proto";

option go_package = "cloud.google.com/go/dataplex/apiv1/dataplexpb;dataplexpb";
option java_multiple_files = true;
option java_outer_classname = "LogsProto";
option java_package = "com.google.cloud.dataplex.v1";

// The payload associated with Discovery data processing.
message DiscoveryEvent {
  // The type of the event.
  enum EventType {
    // An unspecified event type.
    EVENT_TYPE_UNSPECIFIED = 0;

    // An event representing discovery configuration in effect.
    CONFIG = 1;

    // An event representing a metadata entity being created.
    ENTITY_CREATED = 2;

    // An event representing a metadata entity being updated.
    ENTITY_UPDATED = 3;

    // An event representing a metadata entity being deleted.
    ENTITY_DELETED = 4;

    // An event representing a partition being created.
    PARTITION_CREATED = 5;

    // An event representing a partition being updated.
    PARTITION_UPDATED = 6;

    // An event representing a partition being deleted.
    PARTITION_DELETED = 7;
  }

  // The type of the entity.
  enum EntityType {
    // An unspecified event type.
    ENTITY_TYPE_UNSPECIFIED = 0;

    // Entities representing structured data.
    TABLE = 1;

    // Entities representing unstructured data.
    FILESET = 2;
  }

  // Details about configuration events.
  message ConfigDetails {
    // A list of discovery configuration parameters in effect.
    // The keys are the field paths within DiscoverySpec.
    // Eg. includePatterns, excludePatterns, csvOptions.disableTypeInference,
    // etc.
    map<string, string> parameters = 1;
  }

  // Details about the entity.
  message EntityDetails {
    // The name of the entity resource.
    // The name is the fully-qualified resource name.
    string entity = 1;

    // The type of the entity resource.
    EntityType type = 2;
  }

  // Details about the partition.
  message PartitionDetails {
    // The name to the partition resource.
    // The name is the fully-qualified resource name.
    string partition = 1;

    // The name to the containing entity resource.
    // The name is the fully-qualified resource name.
    string entity = 2;

    // The type of the containing entity resource.
    EntityType type = 3;

    // The locations of the data items (e.g., a Cloud Storage objects) sampled
    // for metadata inference.
    repeated string sampled_data_locations = 4;
  }

  // Details about the action.
  message ActionDetails {
    // The type of action.
    // Eg. IncompatibleDataSchema, InvalidDataFormat
    string type = 1;
  }

  // The log message.
  string message = 1;

  // The id of the associated lake.
  string lake_id = 2;

  // The id of the associated zone.
  string zone_id = 3;

  // The id of the associated asset.
  string asset_id = 4;

  // The data location associated with the event.
  string data_location = 5;

  // The type of the event being logged.
  EventType type = 10;

  // Additional details about the event.
  oneof details {
    // Details about discovery configuration in effect.
    ConfigDetails config = 20;

    // Details about the entity associated with the event.
    EntityDetails entity = 21;

    // Details about the partition associated with the event.
    PartitionDetails partition = 22;

    // Details about the action associated with the event.
    ActionDetails action = 23;
  }
}

// The payload associated with Job logs that contains events describing jobs
// that have run within a Lake.
message JobEvent {
  // The type of the job.
  enum Type {
    // Unspecified job type.
    TYPE_UNSPECIFIED = 0;

    // Spark jobs.
    SPARK = 1;

    // Notebook jobs.
    NOTEBOOK = 2;
  }

  // The completion status of the job.
  enum State {
    // Unspecified job state.
    STATE_UNSPECIFIED = 0;

    // Job successfully completed.
    SUCCEEDED = 1;

    // Job was unsuccessful.
    FAILED = 2;

    // Job was cancelled by the user.
    CANCELLED = 3;

    // Job was cancelled or aborted via the service executing the job.
    ABORTED = 4;
  }

  // The service used to execute the job.
  enum Service {
    // Unspecified service.
    SERVICE_UNSPECIFIED = 0;

    // Cloud Dataproc.
    DATAPROC = 1;
  }

  // The log message.
  string message = 1;

  // The unique id identifying the job.
  string job_id = 2;

  // The time when the job started running.
  google.protobuf.Timestamp start_time = 3;

  // The time when the job ended running.
  google.protobuf.Timestamp end_time = 4;

  // The job state on completion.
  State state = 5;

  // The number of retries.
  int32 retries = 6;

  // The type of the job.
  Type type = 7;

  // The service used to execute the job.
  Service service = 8;

  // The reference to the job within the service.
  string service_job = 9;
}

// These messages contain information about sessions within an environment.
// The monitored resource is 'Environment'.
message SessionEvent {
  // The type of the event.
  enum EventType {
    // An unspecified event type.
    EVENT_TYPE_UNSPECIFIED = 0;

    // Event when the session is assigned to a user.
    START = 1;

    // Event for stop of a session.
    STOP = 2;

    // Query events in the session.
    QUERY = 3;

    // Event for creation of a cluster. It is not yet assigned to a user.
    // This comes before START in the sequence
    CREATE = 4;
  }

  // Execution details of the query.
  message QueryDetail {
    // Query Execution engine.
    enum Engine {
      // An unspecified Engine type.
      ENGINE_UNSPECIFIED = 0;

      // Spark-sql engine is specified in Query.
      SPARK_SQL = 1;

      // BigQuery engine is specified in Query.
      BIGQUERY = 2;
    }

    // The unique Query id identifying the query.
    string query_id = 1;

    // The query text executed.
    string query_text = 2;

    // Query Execution engine.
    Engine engine = 3;

    // Time taken for execution of the query.
    google.protobuf.Duration duration = 4;

    // The size of results the query produced.
    int64 result_size_bytes = 5;

    // The data processed by the query.
    int64 data_processed_bytes = 6;
  }

  // The log message.
  string message = 1;

  // The information about the user that created the session. It will be the
  // email address of the user.
  string user_id = 2;

  // Unique identifier for the session.
  string session_id = 3;

  // The type of the event.
  EventType type = 4;

  // Additional information about the Query metadata.
  oneof detail {
    // The execution details of the query.
    QueryDetail query = 5;
  }

  // The status of the event.
  bool event_succeeded = 6;

  // If the session is associated with an environment with fast startup enabled,
  // and was created before being assigned to a user.
  bool fast_startup_enabled = 7;

  // The idle duration of a warm pooled session before it is assigned to user.
  google.protobuf.Duration unassigned_duration = 8;
}

// These messages contain information about the execution of a datascan.
// The monitored resource is 'DataScan'
message DataScanEvent {
  // The type of the data scan.
  enum ScanType {
    // An unspecified data scan type.
    SCAN_TYPE_UNSPECIFIED = 0;

    // Data scan for data profile.
    DATA_PROFILE = 1;

    // Data scan for data quality.
    DATA_QUALITY = 2;
  }

  // The job state of the data scan.
  enum State {
    // Unspecified job state.
    STATE_UNSPECIFIED = 0;

    // Data scan started.
    STARTED = 1;

    // Data scan successfully completed.
    SUCCEEDED = 2;

    // Data scan was unsuccessful.
    FAILED = 3;

    // Data scan was cancelled.
    CANCELLED = 4;
  }

  // The trigger type for the data scan.
  enum Trigger {
    // An unspecified trigger type.
    TRIGGER_UNSPECIFIED = 0;

    // Data scan triggers on demand.
    ON_DEMAND = 1;

    // Data scan triggers as per schedule.
    SCHEDULE = 2;
  }

  // The scope of job for the data scan.
  enum Scope {
    // An unspecified scope type.
    SCOPE_UNSPECIFIED = 0;

    // Data scan runs on all of the data.
    FULL = 1;

    // Data scan runs on incremental data.
    INCREMENTAL = 2;
  }

  // Data profile result for data scan job.
  message DataProfileResult {
    // The count of rows processed in the data scan job.
    int64 row_count = 1;
  }

  // Data quality result for data scan job.
  message DataQualityResult {
    // The count of rows processed in the data scan job.
    int64 row_count = 1;

    // Whether the data quality result was `pass` or not.
    bool passed = 2;

    // The result of each dimension for data quality result.
    // The key of the map is the name of the dimension.
    // The value is the bool value depicting whether the dimension result was
    // `pass` or not.
    map<string, bool> dimension_passed = 3;
  }

  // The data source of the data scan
  string data_source = 1;

  // The identifier of the specific data scan job this log entry is for.
  string job_id = 2;

  // The time when the data scan job started to run.
  google.protobuf.Timestamp start_time = 3;

  // The time when the data scan job finished.
  google.protobuf.Timestamp end_time = 4;

  // The type of the data scan.
  ScanType type = 5;

  // The status of the data scan job.
  State state = 6;

  // The message describing the data scan job event.
  string message = 7;

  // A version identifier of the spec which was used to execute this job.
  string spec_version = 8;

  // The trigger type of the data scan job.
  Trigger trigger = 9;

  // The scope of the data scan (e.g. full, incremental).
  Scope scope = 10;

  // The result of the data scan job.
  oneof result {
    // Data profile result for data profile type data scan.
    DataProfileResult data_profile = 101;

    // Data quality result for data quality type data scan.
    DataQualityResult data_quality = 102;
  }
}
