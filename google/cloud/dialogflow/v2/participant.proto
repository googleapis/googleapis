// Copyright 2021 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package google.cloud.dialogflow.v2;

import "google/api/annotations.proto";
import "google/api/client.proto";
import "google/api/field_behavior.proto";
import "google/api/resource.proto";
import "google/cloud/dialogflow/v2/audio_config.proto";
import "google/cloud/dialogflow/v2/gcs.proto";
import "google/cloud/dialogflow/v2/session.proto";
import "google/protobuf/any.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/field_mask.proto";
import "google/protobuf/struct.proto";
import "google/protobuf/timestamp.proto";
import "google/rpc/status.proto";

option cc_enable_arenas = true;
option csharp_namespace = "Google.Cloud.Dialogflow.V2";
option go_package = "google.golang.org/genproto/googleapis/cloud/dialogflow/v2;dialogflow";
option java_multiple_files = true;
option java_outer_classname = "ParticipantProto";
option java_package = "com.google.cloud.dialogflow.v2";
option objc_class_prefix = "DF";

// Service for managing [Participants][google.cloud.dialogflow.v2.Participant].
service Participants {
  option (google.api.default_host) = "dialogflow.googleapis.com";
  option (google.api.oauth_scopes) =
      "https://www.googleapis.com/auth/cloud-platform,"
      "https://www.googleapis.com/auth/dialogflow";

  // Creates a new participant in a conversation.
  rpc CreateParticipant(CreateParticipantRequest) returns (Participant) {
    option (google.api.http) = {
      post: "/v2/{parent=projects/*/conversations/*}/participants"
      body: "participant"
      additional_bindings {
        post: "/v2/{parent=projects/*/locations/*/conversations/*}/participants"
        body: "participant"
      }
    };
    option (google.api.method_signature) = "parent,participant";
  }

  // Retrieves a conversation participant.
  rpc GetParticipant(GetParticipantRequest) returns (Participant) {
    option (google.api.http) = {
      get: "/v2/{name=projects/*/conversations/*/participants/*}"
      additional_bindings {
        get: "/v2/{name=projects/*/locations/*/conversations/*/participants/*}"
      }
    };
    option (google.api.method_signature) = "name";
  }

  // Returns the list of all participants in the specified conversation.
  rpc ListParticipants(ListParticipantsRequest) returns (ListParticipantsResponse) {
    option (google.api.http) = {
      get: "/v2/{parent=projects/*/conversations/*}/participants"
      additional_bindings {
        get: "/v2/{parent=projects/*/locations/*/conversations/*}/participants"
      }
    };
    option (google.api.method_signature) = "parent";
  }

  // Updates the specified participant.
  rpc UpdateParticipant(UpdateParticipantRequest) returns (Participant) {
    option (google.api.http) = {
      patch: "/v2/{participant.name=projects/*/conversations/*/participants/*}"
      body: "participant"
      additional_bindings {
        patch: "/v2/{participant.name=projects/*/locations/*/conversations/*/participants/*}"
        body: "participant"
      }
    };
    option (google.api.method_signature) = "participant,update_mask";
  }

  // Adds a text (chat, for example), or audio (phone recording, for example)
  // message from a participant into the conversation.
  //
  // Note: Always use agent versions for production traffic
  // sent to virtual agents. See [Versions and
  // environments](https://cloud.google.com/dialogflow/es/docs/agents-versions).
  rpc AnalyzeContent(AnalyzeContentRequest) returns (AnalyzeContentResponse) {
    option (google.api.http) = {
      post: "/v2/{participant=projects/*/conversations/*/participants/*}:analyzeContent"
      body: "*"
      additional_bindings {
        post: "/v2/{participant=projects/*/locations/*/conversations/*/participants/*}:analyzeContent"
        body: "*"
      }
    };
    option (google.api.method_signature) = "participant,text_input";
    option (google.api.method_signature) = "participant,event_input";
  }

  // Gets suggested articles for a participant based on specific historical
  // messages.
  rpc SuggestArticles(SuggestArticlesRequest) returns (SuggestArticlesResponse) {
    option (google.api.http) = {
      post: "/v2/{parent=projects/*/conversations/*/participants/*}/suggestions:suggestArticles"
      body: "*"
      additional_bindings {
        post: "/v2/{parent=projects/*/locations/*/conversations/*/participants/*}/suggestions:suggestArticles"
        body: "*"
      }
    };
    option (google.api.method_signature) = "parent";
  }

  // Gets suggested faq answers for a participant based on specific historical
  // messages.
  rpc SuggestFaqAnswers(SuggestFaqAnswersRequest) returns (SuggestFaqAnswersResponse) {
    option (google.api.http) = {
      post: "/v2/{parent=projects/*/conversations/*/participants/*}/suggestions:suggestFaqAnswers"
      body: "*"
      additional_bindings {
        post: "/v2/{parent=projects/*/locations/*/conversations/*/participants/*}/suggestions:suggestFaqAnswers"
        body: "*"
      }
    };
    option (google.api.method_signature) = "parent";
  }
}

// Represents a conversation participant (human agent, virtual agent, end-user).
message Participant {
  option (google.api.resource) = {
    type: "dialogflow.googleapis.com/Participant"
    pattern: "projects/{project}/conversations/{conversation}/participants/{participant}"
    pattern: "projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}"
  };

  // Enumeration of the roles a participant can play in a conversation.
  enum Role {
    // Participant role not set.
    ROLE_UNSPECIFIED = 0;

    // Participant is a human agent.
    HUMAN_AGENT = 1;

    // Participant is an automated agent, such as a Dialogflow agent.
    AUTOMATED_AGENT = 2;

    // Participant is an end user that has called or chatted with
    // Dialogflow services.
    END_USER = 3;
  }

  // Optional. The unique identifier of this participant.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
  string name = 1 [(google.api.field_behavior) = OPTIONAL];

  // Immutable. The role this participant plays in the conversation. This field must be set
  // during participant creation and is then immutable.
  Role role = 2 [(google.api.field_behavior) = IMMUTABLE];

  // Optional. Label applied to streams representing this participant in SIPREC
  // XML metadata and SDP. This is used to assign transcriptions from that
  // media stream to this participant. This field can be updated.
  string sip_recording_media_label = 6 [(google.api.field_behavior) = OPTIONAL];

  // Optional. Key-value filters on the metadata of documents returned by article
  // suggestion. If specified, article suggestion only returns suggested
  // documents that match all filters in their [Document.metadata][google.cloud.dialogflow.v2.Document.metadata]. Multiple
  // values for a metadata key should be concatenated by comma. For example,
  // filters to match all documents that have 'US' or 'CA' in their market
  // metadata values and 'agent' in their user metadata values will be
  // ```
  // documents_metadata_filters {
  //   key: "market"
  //   value: "US,CA"
  // }
  // documents_metadata_filters {
  //   key: "user"
  //   value: "agent"
  // }
  // ```
  map<string, string> documents_metadata_filters = 8 [(google.api.field_behavior) = OPTIONAL];
}

// Represents a message posted into a conversation.
message Message {
  option (google.api.resource) = {
    type: "dialogflow.googleapis.com/Message"
    pattern: "projects/{project}/conversations/{conversation}/messages/{message}"
    pattern: "projects/{project}/locations/{location}/conversations/{conversation}/messages/{message}"
  };

  // The unique identifier of the message.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/messages/<Message ID>`.
  string name = 1;

  // Required. The message content.
  string content = 2 [(google.api.field_behavior) = REQUIRED];

  // Optional. The message language.
  // This should be a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
  // language tag. Example: "en-US".
  string language_code = 3 [(google.api.field_behavior) = OPTIONAL];

  // Output only. The participant that sends this message.
  string participant = 4 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. The role of the participant.
  Participant.Role participant_role = 5 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. The time when the message was created.
  google.protobuf.Timestamp create_time = 6 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. The annotation for the message.
  MessageAnnotation message_annotation = 7 [(google.api.field_behavior) = OUTPUT_ONLY];
}

// The request message for [Participants.CreateParticipant][google.cloud.dialogflow.v2.Participants.CreateParticipant].
message CreateParticipantRequest {
  // Required. Resource identifier of the conversation adding the participant.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>`.
  string parent = 1 [
    (google.api.field_behavior) = REQUIRED,
    (google.api.resource_reference) = {
      child_type: "dialogflow.googleapis.com/Participant"
    }
  ];

  // Required. The participant to create.
  Participant participant = 2 [(google.api.field_behavior) = REQUIRED];
}

// The request message for [Participants.GetParticipant][google.cloud.dialogflow.v2.Participants.GetParticipant].
message GetParticipantRequest {
  // Required. The name of the participant. Format:
  // `projects/<Project ID>/locations/<Location ID>/conversations/<Conversation
  // ID>/participants/<Participant ID>`.
  string name = 1 [
    (google.api.field_behavior) = REQUIRED,
    (google.api.resource_reference) = {
      type: "dialogflow.googleapis.com/Participant"
    }
  ];
}

// The request message for [Participants.ListParticipants][google.cloud.dialogflow.v2.Participants.ListParticipants].
message ListParticipantsRequest {
  // Required. The conversation to list all participants from.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>`.
  string parent = 1 [
    (google.api.field_behavior) = REQUIRED,
    (google.api.resource_reference) = {
      child_type: "dialogflow.googleapis.com/Participant"
    }
  ];

  // Optional. The maximum number of items to return in a single page. By
  // default 100 and at most 1000.
  int32 page_size = 2 [(google.api.field_behavior) = OPTIONAL];

  // Optional. The next_page_token value returned from a previous list request.
  string page_token = 3 [(google.api.field_behavior) = OPTIONAL];
}

// The response message for [Participants.ListParticipants][google.cloud.dialogflow.v2.Participants.ListParticipants].
message ListParticipantsResponse {
  // The list of participants. There is a maximum number of items
  // returned based on the page_size field in the request.
  repeated Participant participants = 1;

  // Token to retrieve the next page of results or empty if there are no
  // more results in the list.
  string next_page_token = 2;
}

// The request message for [Participants.UpdateParticipant][google.cloud.dialogflow.v2.Participants.UpdateParticipant].
message UpdateParticipantRequest {
  // Required. The participant to update.
  Participant participant = 1 [(google.api.field_behavior) = REQUIRED];

  // Required. The mask to specify which fields to update.
  google.protobuf.FieldMask update_mask = 2 [(google.api.field_behavior) = REQUIRED];
}

// The request message for [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent].
message AnalyzeContentRequest {
  // Required. The name of the participant this text comes from.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
  string participant = 1 [
    (google.api.field_behavior) = REQUIRED,
    (google.api.resource_reference) = {
      type: "dialogflow.googleapis.com/Participant"
    }
  ];

  // Required. The input content.
  oneof input {
    // The natural language text to be processed.
    TextInput text_input = 6;

    // An input event to send to Dialogflow.
    EventInput event_input = 8;
  }

  // Speech synthesis configuration.
  // The speech synthesis settings for a virtual agent that may be configured
  // for the associated conversation profile are not used when calling
  // AnalyzeContent. If this configuration is not supplied, speech synthesis
  // is disabled.
  OutputAudioConfig reply_audio_config = 5;

  // Parameters for a Dialogflow virtual-agent query.
  QueryParameters query_params = 9;

  // Parameters for a human assist query.
  AssistQueryParameters assist_query_params = 14;

  // A unique identifier for this request. Restricted to 36 ASCII characters.
  // A random UUID is recommended.
  // This request is only idempotent if a `request_id` is provided.
  string request_id = 11;
}

// The message in the response that indicates the parameters of DTMF.
message DtmfParameters {
  // Indicates whether DTMF input can be handled in the next request.
  bool accepts_dtmf_input = 1;
}

// The response message for [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent].
message AnalyzeContentResponse {
  // The output text content.
  // This field is set if the automated agent responded with text to show to
  // the user.
  string reply_text = 1;

  // The audio data bytes encoded as specified in the request.
  // This field is set if:
  //
  //  - `reply_audio_config` was specified in the request, or
  //  - The automated agent responded with audio to play to the user. In such
  //    case, `reply_audio.config` contains settings used to synthesize the
  //    speech.
  //
  // In some scenarios, multiple output audio fields may be present in the
  // response structure. In these cases, only the top-most-level audio output
  // has content.
  OutputAudio reply_audio = 2;

  // Only set if a Dialogflow automated agent has responded.
  // Note that: [AutomatedAgentReply.detect_intent_response.output_audio][]
  // and [AutomatedAgentReply.detect_intent_response.output_audio_config][]
  // are always empty, use [reply_audio][google.cloud.dialogflow.v2.AnalyzeContentResponse.reply_audio] instead.
  AutomatedAgentReply automated_agent_reply = 3;

  // Message analyzed by CCAI.
  Message message = 5;

  // The suggestions for most recent human agent. The order is the same as
  // [HumanAgentAssistantConfig.SuggestionConfig.feature_configs][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.SuggestionConfig.feature_configs] of
  // [HumanAgentAssistantConfig.human_agent_suggestion_config][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.human_agent_suggestion_config].
  repeated SuggestionResult human_agent_suggestion_results = 6;

  // The suggestions for end user. The order is the same as
  // [HumanAgentAssistantConfig.SuggestionConfig.feature_configs][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.SuggestionConfig.feature_configs] of
  // [HumanAgentAssistantConfig.end_user_suggestion_config][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.end_user_suggestion_config].
  repeated SuggestionResult end_user_suggestion_results = 7;

  // Indicates the parameters of DTMF.
  DtmfParameters dtmf_parameters = 9;
}

// The request message for [Participants.SuggestArticles][google.cloud.dialogflow.v2.Participants.SuggestArticles].
message SuggestArticlesRequest {
  // Required. The name of the participant to fetch suggestion for.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
  string parent = 1 [
    (google.api.field_behavior) = REQUIRED,
    (google.api.resource_reference) = {
      type: "dialogflow.googleapis.com/Participant"
    }
  ];

  // The name of the latest conversation message to compile suggestion
  // for. If empty, it will be the latest message of the conversation.
  //
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/messages/<Message ID>`.
  string latest_message = 2 [(google.api.resource_reference) = {
                               type: "dialogflow.googleapis.com/Message"
                             }];

  // Max number of messages prior to and including
  // [latest_message][google.cloud.dialogflow.v2.SuggestArticlesRequest.latest_message] to use as context
  // when compiling the suggestion. By default 20 and at most 50.
  int32 context_size = 3;

  // Parameters for a human assist query.
  AssistQueryParameters assist_query_params = 4;
}

// The response message for [Participants.SuggestArticles][google.cloud.dialogflow.v2.Participants.SuggestArticles].
message SuggestArticlesResponse {
  // Articles ordered by score in descending order.
  repeated ArticleAnswer article_answers = 1;

  // The name of the latest conversation message used to compile
  // suggestion for.
  //
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/messages/<Message ID>`.
  string latest_message = 2;

  // Number of messages prior to and including
  // [latest_message][google.cloud.dialogflow.v2.SuggestArticlesResponse.latest_message] to compile the
  // suggestion. It may be smaller than the
  // [SuggestArticlesRequest.context_size][google.cloud.dialogflow.v2.SuggestArticlesRequest.context_size] field in the request if there
  // aren't that many messages in the conversation.
  int32 context_size = 3;
}

// The request message for [Participants.SuggestFaqAnswers][google.cloud.dialogflow.v2.Participants.SuggestFaqAnswers].
message SuggestFaqAnswersRequest {
  // Required. The name of the participant to fetch suggestion for.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
  string parent = 1 [
    (google.api.field_behavior) = REQUIRED,
    (google.api.resource_reference) = {
      type: "dialogflow.googleapis.com/Participant"
    }
  ];

  // The name of the latest conversation message to compile suggestion
  // for. If empty, it will be the latest message of the conversation.
  //
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/messages/<Message ID>`.
  string latest_message = 2 [(google.api.resource_reference) = {
                               type: "dialogflow.googleapis.com/Message"
                             }];

  // Max number of messages prior to and including
  // [latest_message] to use as context when compiling the
  // suggestion. By default 20 and at most 50.
  int32 context_size = 3;

  // Parameters for a human assist query.
  AssistQueryParameters assist_query_params = 4;
}

// The request message for [Participants.SuggestFaqAnswers][google.cloud.dialogflow.v2.Participants.SuggestFaqAnswers].
message SuggestFaqAnswersResponse {
  // Answers extracted from FAQ documents.
  repeated FaqAnswer faq_answers = 1;

  // The name of the latest conversation message used to compile
  // suggestion for.
  //
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/conversations/<Conversation ID>/messages/<Message ID>`.
  string latest_message = 2;

  // Number of messages prior to and including
  // [latest_message][google.cloud.dialogflow.v2.SuggestFaqAnswersResponse.latest_message] to compile the
  // suggestion. It may be smaller than the
  // [SuggestFaqAnswersRequest.context_size][google.cloud.dialogflow.v2.SuggestFaqAnswersRequest.context_size] field in the request if there
  // aren't that many messages in the conversation.
  int32 context_size = 3;
}

// Represents the natural language speech audio to be played to the end user.
message OutputAudio {
  // Instructs the speech synthesizer how to generate the speech
  // audio.
  OutputAudioConfig config = 1;

  // The natural language speech audio.
  bytes audio = 2;
}

// Represents a response from an automated agent.
message AutomatedAgentReply {
  // Represents different automated agent reply types.
  enum AutomatedAgentReplyType {
    // Not specified. This should never happen.
    AUTOMATED_AGENT_REPLY_TYPE_UNSPECIFIED = 0;

    // Partial reply. e.g. Aggregated responses in a `Fulfillment` that enables
    // `return_partial_response` can be returned as partial reply.
    // WARNING: partial reply is not eligible for barge-in.
    PARTIAL = 1;

    // Final reply.
    FINAL = 2;
  }

  // Response of the Dialogflow [Sessions.DetectIntent][google.cloud.dialogflow.v2.Sessions.DetectIntent] call.
  DetectIntentResponse detect_intent_response = 1;

  // AutomatedAgentReply type.
  AutomatedAgentReplyType automated_agent_reply_type = 7;

  // Indicates whether the partial automated agent reply is interruptible when a
  // later reply message arrives. e.g. if the agent specified some music as
  // partial response, it can be cancelled.
  bool allow_cancellation = 8;
}

// Represents article answer.
message ArticleAnswer {
  // The article title.
  string title = 1;

  // The article URI.
  string uri = 2;

  // Article snippets.
  repeated string snippets = 3;

  // Article match confidence.
  // The system's confidence score that this article is a good match for this
  // conversation, as a value from 0.0 (completely uncertain) to 1.0
  // (completely certain).
  float confidence = 4;

  // A map that contains metadata about the answer and the
  // document from which it originates.
  map<string, string> metadata = 5;

  // The name of answer record, in the format of
  // "projects/<Project ID>/locations/<Location ID>/answerRecords/<Answer Record
  // ID>"
  string answer_record = 6;
}

// Represents answer from "frequently asked questions".
message FaqAnswer {
  // The piece of text from the `source` knowledge base document.
  string answer = 1;

  // The system's confidence score that this Knowledge answer is a good match
  // for this conversational query, range from 0.0 (completely uncertain)
  // to 1.0 (completely certain).
  float confidence = 2;

  // The corresponding FAQ question.
  string question = 3;

  // Indicates which Knowledge Document this answer was extracted
  // from.
  // Format: `projects/<Project ID>/locations/<Location
  // ID>/agent/knowledgeBases/<Knowledge Base ID>/documents/<Document ID>`.
  string source = 4;

  // A map that contains metadata about the answer and the
  // document from which it originates.
  map<string, string> metadata = 5;

  // The name of answer record, in the format of
  // "projects/<Project ID>/locations/<Location ID>/answerRecords/<Answer Record
  // ID>"
  string answer_record = 6;
}

// One response of different type of suggestion response which is used in
// the response of [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent] and
// [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent], as well as [HumanAgentAssistantEvent][google.cloud.dialogflow.v2.HumanAgentAssistantEvent].
message SuggestionResult {
  // Different type of suggestion response.
  oneof suggestion_response {
    // Error status if the request failed.
    google.rpc.Status error = 1;

    // SuggestArticlesResponse if request is for ARTICLE_SUGGESTION.
    SuggestArticlesResponse suggest_articles_response = 2;

    // SuggestFaqAnswersResponse if request is for FAQ_ANSWER.
    SuggestFaqAnswersResponse suggest_faq_answers_response = 3;
  }
}

// Represents a part of a message possibly annotated with an entity. The part
// can be an entity or purely a part of the message between two entities or
// message start/end.
message AnnotatedMessagePart {
  // A part of a message possibly annotated with an entity.
  string text = 1;

  // The [Dialogflow system entity
  // type](https://cloud.google.com/dialogflow/docs/reference/system-entities)
  // of this message part. If this is empty, Dialogflow could not annotate the
  // phrase part with a system entity.
  string entity_type = 2;

  // The [Dialogflow system entity formatted value
  // ](https://cloud.google.com/dialogflow/docs/reference/system-entities) of
  // this message part. For example for a system entity of type
  // `@sys.unit-currency`, this may contain:
  // <pre>
  // {
  //   "amount": 5,
  //   "currency": "USD"
  // }
  // </pre>
  google.protobuf.Value formatted_value = 3;
}

// Represents the result of annotation for the message.
message MessageAnnotation {
  // The collection of annotated message parts ordered by their
  // position in the message. You can recover the annotated message by
  // concatenating [AnnotatedMessagePart.text].
  repeated AnnotatedMessagePart parts = 1;

  // Indicates whether the text message contains entities.
  bool contain_entities = 2;
}

// Represents the parameters of human assist query.
message AssistQueryParameters {
  // Key-value filters on the metadata of documents returned by article
  // suggestion. If specified, article suggestion only returns suggested
  // documents that match all filters in their [Document.metadata][google.cloud.dialogflow.v2.Document.metadata]. Multiple
  // values for a metadata key should be concatenated by comma. For example,
  // filters to match all documents that have 'US' or 'CA' in their market
  // metadata values and 'agent' in their user metadata values will be
  // ```
  // documents_metadata_filters {
  //   key: "market"
  //   value: "US,CA"
  // }
  // documents_metadata_filters {
  //   key: "user"
  //   value: "agent"
  // }
  // ```
  map<string, string> documents_metadata_filters = 1;
}
